{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP09042020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNB7RHtsPc67xWlhF21DG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doguma/NLP_Fall2020/blob/master/NLP09042020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEcHDs_NtC1J",
        "colab_type": "text"
      },
      "source": [
        "# **NLP Lab 1**\n",
        " September 4th, *2020*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnKyQCb8tTgL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "> - Library Import\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vws20JXrnB9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.corpus.reader.wordnet import NOUN\n",
        "from nltk.corpus import wordnet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzd6_9B5nirE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the data\n",
        "shakespeare_url = \"http://www.cs.columbia.edu/~sarahita/CL/lab1/shakespeare.txt\"\n",
        "news_url = \"http://www.cs.columbia.edu/~sarahita/CL/lab1/news.txt\"\n",
        "swbd_url = \"http://www.cs.columbia.edu/~sarahita/CL/lab1/swbd.txt\"\n",
        "\n",
        "# read url .txt file into string \"data\"\n",
        "def get_data(url):\n",
        "  data = urllib.request.urlopen(url).read().decode('utf-8')\n",
        "  return data\n",
        "\n",
        "shakespeare_data = get_data(shakespeare_url)\n",
        "news_data = get_data(news_url)\n",
        "swbd_data = get_data(swbd_url)\n",
        "\n",
        "\n",
        "shakespeare_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRauxqPOtB_T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> - Tokenize the string : word_tokenize()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW-GltoMjWiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the string\n",
        "shakespeare_tokenized = word_tokenize(shakespeare_data)\n",
        "news_tokenized = word_tokenize(news_data)\n",
        "swbd_tokenized = word_tokenize(swbd_data)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uot2K4tsuuCZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count number of total tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m0Yu8jbu1TA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "389e399a-e8a7-43f9-8d31-d6ae851f8784"
      },
      "source": [
        "# count number of tokens\n",
        "print(\"Number of words in shakespeare txt: \" , len(shakespeare_tokenized))\n",
        "print(\"Number of words in news txt: \" , len(news_tokenized))\n",
        "print(\"Number of words in swbd txt: \" , len(swbd_tokenized))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  1228950\n",
            "Number of words in news txt:  33378\n",
            "Number of words in swbd txt:  96222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Py5f1Ou2yP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count number of word types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUBiw96EjsD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "738ba8bd-8b1c-4159-ef23-baeeb700fbf2"
      },
      "source": [
        "# count number of tokens - type of unique word vocabulary\n",
        "print(\"Number of words in shakespeare txt: \" , len(Counter(shakespeare_tokenized).most_common()))\n",
        "print(\"Number of words in news txt: \" , len(Counter(news_tokenized).most_common()))\n",
        "print(\"Number of words in swbd txt: \" , len(Counter(swbd_tokenized).most_common()))"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  39559\n",
            "Number of words in news txt:  7248\n",
            "Number of words in swbd txt:  5225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cauq9Kzgu-im",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> - **Remove punctuations** : re.sub()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjO684ZhWKNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Removing punctuations in string \n",
        "shakespeare_data_nopunc = re.sub('[^a-zA-Z]', \" \", shakespeare_data)\n",
        "shakespeare_data_nopunc\n",
        "\n",
        "news_data_nopunc = re.sub('[^a-zA-Z]', \" \", news_data)\n",
        "swbd_data_nopunc = re.sub('[^a-zA-Z]', \" \", swbd_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP_gjx1SvLVz",
        "colab_type": "text"
      },
      "source": [
        "> - Tokenize the string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEfc0RcHaDlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the string\n",
        "shakespeare_tokenized = word_tokenize(shakespeare_data_nopunc)\n",
        "news_tokenized = word_tokenize(news_data_nopunc)\n",
        "swbd_tokenized = word_tokenize(swbd_data_nopunc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoNHIHpAvUrL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7sI3JOMvUAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "79bb9592-6512-4bcd-ce5b-c252330ac580"
      },
      "source": [
        "# count number of tokens\n",
        "print(\"Number of words in shakespeare txt: \" , len(shakespeare_tokenized))\n",
        "print(\"Number of words in news txt: \" , len(news_tokenized))\n",
        "print(\"Number of words in swbd txt: \" , len(swbd_tokenized))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  991641\n",
            "Number of words in news txt:  30383\n",
            "Number of words in swbd txt:  73378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMumbu-DvHa8",
        "colab_type": "text"
      },
      "source": [
        "> - Count number of word types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWQJcp54jFKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "388f8931-a297-4b51-9ec8-34b8d12f7b4d"
      },
      "source": [
        "# count number of tokens - type of unique word vocabulary\n",
        "print(\"Number of words in shakespeare txt: \" , len(Counter(shakespeare_tokenized).most_common()))\n",
        "print(\"Number of words in news txt: \" , len(Counter(news_tokenized).most_common()))\n",
        "print(\"Number of words in swbd txt: \" , len(Counter(swbd_tokenized).most_common()))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  32195\n",
            "Number of words in news txt:  6798\n",
            "Number of words in swbd txt:  4690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAvd2KxNvnex",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> - **Case folding** : change all text to lowercase\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnjOrC4QvVl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change text to lowercase\n",
        "low_shakes_tokenized = [w.lower() for w in shakespeare_tokenized]\n",
        "low_news_tokenized = [w.lower() for w in news_tokenized]\n",
        "low_swbd_tokenized = [w.lower() for w in swbd_tokenized]"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLlz56-bwtBJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO_PtI8hwsSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a859ec4d-9e20-4f25-e8a2-0e5268041355"
      },
      "source": [
        "# count number of tokens\n",
        "print(\"Number of words in shakespeare txt: \" , len(low_shakes_tokenized))\n",
        "print(\"Number of words in news txt: \" , len(news_tokenized))\n",
        "print(\"Number of words in swbd txt: \" , len(swbd_tokenized))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  991641\n",
            "Number of words in news txt:  30383\n",
            "Number of words in swbd txt:  73378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGdBk43BwhJW",
        "colab_type": "text"
      },
      "source": [
        "> - Count number of word types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n_mTZIOnIqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5c08dcb-eea9-486d-9db8-b3e6ae17c327"
      },
      "source": [
        "# count number of word types\n",
        "print(\"Number of words in shakespeare txt: \" , len(Counter(low_shakes_tokenized).most_common()))\n",
        "print(\"Number of words in news txt: \" , len(Counter(low_news_tokenized).most_common()))\n",
        "print(\"Number of words in swbd txt: \" , len(Counter(low_swbd_tokenized).most_common()))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  25766\n",
            "Number of words in news txt:  6060\n",
            "Number of words in swbd txt:  4310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx6KdNkHw-z5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "> - **Stemming** : use Porter stemmer to stem the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bElsiryLvR7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Porter stemmer\n",
        "def stemSentence(sentence):\n",
        "    stem_sentence=[]\n",
        "    for word in sentence:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jihr79jkMb1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmed_shakespeare = stemSentence(low_shakes_tokenized)\n",
        "stemmed_news = stemSentence(low_news_tokenized)\n",
        "stemmed_swbd = stemSentence(low_swbd_tokenized)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcTohEQv0F4e",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Tokenize the string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-BIkjxYZDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the string\n",
        "stemmed_shakespeare = word_tokenize(stemmed_shakespeare)\n",
        "stemmed_news = word_tokenize(stemmed_news)\n",
        "stemmed_swbd = word_tokenize(stemmed_swbd)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-nG4bPI0Bkv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJLchdARyEUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19ec9474-e174-4c63-e18a-675bed682c68"
      },
      "source": [
        "# count number of tokens\n",
        "print(\"Number of words in shakespeare txt: \" , len(stemmed_shakespeare))\n",
        "print(\"Number of words in news txt: \" , len(stemmed_news))\n",
        "print(\"Number of words in swbd txt: \" , len(stemmed_swbd))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  991641\n",
            "Number of words in news txt:  30383\n",
            "Number of words in swbd txt:  73378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1UYDBWF0Cdf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> - Count total number of word types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rfISql_nKDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "513e8a7b-46fb-4e22-d81b-191775dd2a3d"
      },
      "source": [
        "# count number of word types\n",
        "print(\"Number of words in shakespeare txt: \" , len(Counter(stemmed_shakespeare).most_common()))\n",
        "print(\"Number of words in news txt: \" , len(Counter(stemmed_news).most_common()))\n",
        "print(\"Number of words in swbd txt: \" , len(Counter(stemmed_swbd).most_common()))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  15976\n",
            "Number of words in news txt:  4525\n",
            "Number of words in swbd txt:  3198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77O1z4_JxGf-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "> - **Lemmatize** : used Wordnet Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhvEOtb0WdDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wordnet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_shakespeare = ' '.join([lemmatizer.lemmatize(w) for w in stemmed_shakespeare])\n",
        "lemmatized_news = ' '.join([lemmatizer.lemmatize(w) for w in stemmed_news])\n",
        "lemmatized_swbd = ' '.join([lemmatizer.lemmatize(w) for w in stemmed_swbd])"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6F_cqsq0cjY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> - Tokenize the string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsxhnMGhbYxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the string\n",
        "lemmatized_shakespeare = word_tokenize(lemmatized_shakespeare)\n",
        "lemmatized_news = word_tokenize(lemmatized_news)\n",
        "lemmatized_swbd = word_tokenize(lemmatized_swbd)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSwmLnZ0ZRx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> - Count total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKB0iCIWzyhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a7b523a5-fca3-4045-95cc-6abe7c295401"
      },
      "source": [
        "# count number of tokens\n",
        "print(\"Number of words in shakespeare txt: \" , len(lemmatized_shakespeare))\n",
        "print(\"Number of words in news txt: \" , len(lemmatized_news))\n",
        "print(\"Number of words in swbd txt: \" , len(lemmatized_swbd))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  991641\n",
            "Number of words in news txt:  30383\n",
            "Number of words in swbd txt:  73378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKAiXJcb0aC8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> - Count total number of word types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLx_290qjhU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "93413b6d-373f-4fd6-9bc4-77aa0249a48f"
      },
      "source": [
        "# count number of word types\n",
        "print(\"Number of words in shakespeare txt: \" , len(Counter(lemmatized_shakespeare).most_common()))\n",
        "print(\"Number of words in news txt: \" , len(Counter(lemmatized_news).most_common()))\n",
        "print(\"Number of words in swbd txt: \" , len(Counter(lemmatized_swbd).most_common()))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in shakespeare txt:  15895\n",
            "Number of words in news txt:  4512\n",
            "Number of words in swbd txt:  3191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JO_OYrZxu5j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        ">  Top 10 most common words on each text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oOTXOVSif7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "376c4729-e7f8-417e-ea28-d16e546030d4"
      },
      "source": [
        "Counter(lemmatized_shakespeare).most_common(10)  "
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 30232),\n",
              " ('and', 28467),\n",
              " ('i', 23953),\n",
              " ('a', 22571),\n",
              " ('to', 21302),\n",
              " ('of', 18834),\n",
              " ('you', 14690),\n",
              " ('my', 13199),\n",
              " ('in', 12382),\n",
              " ('that', 12256)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-KzT4cfqTeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(lemmatized_news).most_common(10)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IK81Ej_hdd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(lemmatized_swbd).most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
